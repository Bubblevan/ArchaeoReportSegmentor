# Archaeology Report Segmentor


本项目旨在对考古报告中的线图进行自动化裁剪，作为“互联网+”智载千古项目的器物分割模块算法。

## 数据集

- **已打好标签的数据集**: [yolov10/datasets/mycoco](https://pan.baidu.com/s/1FHKpx75WZ3GqDhQGqIWRkg?pwd=xswl )
- **原始考古报告**: [project/source](https://pan.baidu.com/s/1yf4QBHwBcJJiHBvOMQIsDw?pwd=xswl )

## 项目概述

本脚本涉及一种基于深度学习的考古线图提取方法，通过图像识别和自然语言处理技术，自动识别、裁剪和命名考古文献中的线图、图注、序号和器物等元素，以实现考古数据的可视化分析和存储。系统结合了目标检测模型 YOLO v10 与 OCR 文字识别模型 Paddle OCR，实现了对考古文献中线图、图注、序号和器物等要素的自动化识别、裁剪与保存。

### 实施流程

1. **图像处理**: 将考古报告的 PDF 文件转换为高分辨率图像（如 JPEG 或 PNG 格式）。
2. **目标检测**: 使用 YOLO v10 目标检测模型对考古文献中的线图元素进行自动识别和坐标提取。
3. **文本识别**: 结合 Paddle OCR 对识别出的图注和序号进行 OCR 文本识别。
4. **图像裁剪与命名**: 将识别结果和裁剪后的图像按规定格式命名保存，以便于后续数据分析和考古文献整理。

### YOLO v10 模型

YOLO v10 模型因其高效的目标检测能力被用于本发明的线图提取。考虑到 YOLO 最新版本 v11 的文档和教程较少，部署困难，因此本实施例中选择了 YOLO v10 作为最佳模型版本。

#### 模型训练

- **数据集构建**: 使用考古报告中常见的器物图片（如陶罐、石斧、玉环等）和六个墓葬图样本构建数据集。
- **训练数据**: 包括来自多份考古报告的标注图像 2400 张。
- **训练配置**: 通过构建 yaml 配置文件，将数据集路径、类别数和类别信息写入其中，并在模型训练中加载 YOLO v10 的预训练权重，在 100 个 epoch 内完成训练。

#### 模型预测

在使用 YOLO v10 对考古报告图像进行预测时，设置预测命令以生成结果坐标文件（txt 格式），包含每个预测框的坐标信息。识别过程中生成的预测框类别包括：

- 整体框（类别 4）
- 线图框（类别 1）
- 序号框（类别 2）
- 图注框（类别 3）

每个框的坐标数据和类别信息都被记录到 txt 文件中，为后续的图像裁剪和命名处理提供了基础。

### Paddle OCR 模型

在完成坐标提取后，采用 Paddle OCR 对每个图注和序号框进行 OCR 识别。OCR 模型的选择基于 Paddle OCR 的高精度中文识别能力，尤其适用于考古文献中包含大量中文图注的情况。使用 OCR 识别出的图注和序号信息，用以生成裁剪图像的文件名，裁剪后的文件按“图注 + 序号”的格式命名。

#### 裁剪命名流程

1. 将识别到的整体框作为基准，提取其中的图注、序号、器物等元素。
2. 对每个图注框进行 OCR 识别，将提取的文本作为命名依据。
3. 如果图注框中没有识别到文字，则引用前一个图注命名。
4. 将裁剪后的器物图像与图注和序号组合命名，确保图像和文本信息的一一对应。

### 创新点

本发明创新地将 YOLO v10 目标检测模型与 Paddle OCR 文字识别模型结合应用于考古文献的线图识别和提取，替代了传统 OCR 技术难以处理的复杂线图识别问题。自动化的图像裁剪流程极大提高了考古文献分析的效率，减少了人为干预的错误风险。与传统人工操作相比，自动提取流程大大提高了考古文献处理的准确性和可操作性。

### 适用性

为适应不同类型的考古文献，本发明的 YOLO 模型支持通过增加数据集样本多样性来提升识别精度。此外，模型能够根据考古图像的特殊格式适应更多类型的线图识别和处理需求，确保该自动化提取流程的广泛适用性。

本项目为对考古报告中的线图实行自动化裁剪的算法部分，使用yolov10作为基础。

已打好标签的数据集见 yolov10/datasets/mycoco
